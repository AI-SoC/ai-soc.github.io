<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Titillium Web">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="script/aisoc.css" type="text/css" />
<title>Heuijee Yun (Integrated Ph.D. Candidate)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">AI-S<sup><font size=1>2</font></sup>oC Lab<img src=images/logo.jpg width=20 ></div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="l_professor.html">Professor</a></div>
<div class="menu-item"><a href="l_members.html">Members</a></div>
<div class="menu-item"><a href="l_interns.html">Candidates</a></div>
<div class="menu-item"><a href="l_alumni.html">Alumni</a></div>
<div class="menu-item"><a href="l_research.html">Research</a></div>
<div class="menu-item"><a href="l_equipment.html">Equipment</a></div>
<div class="menu-item"><a href="l_symposium.html">Symposium</a></div>
<div class="menu-item"><a href="l_tutorials.html">Tutorials</a></div>
<div class="menu-item"><a href="l_photos.html">Photos</a></div>
<div class="menu-category">For Candidates</div>
<div class="menu-item"><a href="s_courses.html">Preparation</a></div>
<div class="menu-item"><a href="l_benefit.html">Benefit</a></div>
<div class="menu-item"><a href="s_contact.html">Contact</a></div>
<div class="menu-category">Publication</div>
<div class="menu-item"><a href="l_journals.html">Journals</a></div>
<div class="menu-item"><a href="l_conferences.html">Conferences</a></div>
<div class="menu-item"><a href="l_presentation.html">Presentations</a></div>
<div class="menu-item"><a href="l_mybooks.html">Authored&nbsp;Books</a></div>
<div class="menu-item"><a href="l_patents.html">Patents</a></div>
<div class="menu-category">Teaching</div>
<div class="menu-item"><a href="l_courses.html">Courses</a></div>
<div class="menu-item"><a href="l_study.html">Study</a></div>
<div class="menu-item"><a href="c_lpsoc.html">Low&nbsp;Power&nbsp;SoC</a></div>
<div class="menu-item"><a href="c_cprog.html">C&nbsp;Programming</a></div>
<div class="menu-item"><a href="c_dsp.html">DSP</a></div>
<div class="menu-category">Useful Data</div>
<div class="menu-item"><a href="u_software.html">Software</a></div>
<div class="menu-item"><a href="u_must_books.html">Must-Read&nbsp;Books</a></div>
<div class="menu-category">Member Profile (20)</div>
<div class="menu-item"><a href="m_shcho.html">(Ph.D)&nbsp;S.&nbsp;H.&nbsp;Cho</a></div>
<div class="menu-item"><a href="m_shhong.html">(Ph.D)&nbsp;S.&nbsp;H.&nbsp;Hong</a></div>
<div class="menu-item"><a href="m_mjkang.html">(Ph.D)&nbsp;M.&nbsp;J.&nbsp;Kang</a></div>
<div class="menu-item"><a href="m_jhan.html">(Ph.D)&nbsp;J.&nbsp;H.&nbsp;An</a></div>
<div class="menu-item"><a href="m_shwlee.html">(Ph.D)&nbsp;S.&nbsp;H.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_hjyoun.html" class="current">(Ph.D)&nbsp;H.&nbsp;J.&nbsp;Yun</a></div>
<div class="menu-item"><a href="m_yhlee.html">(Ph.D)&nbsp;Y.&nbsp;H.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_shpark.html">(Ph.D)&nbsp;S.&nbsp;H.&nbsp;Park</a></div>
<div class="menu-item"><a href="m_mjkim.html">(Ph.D)&nbsp;M.&nbsp;J.&nbsp;Kim</a></div>
<div class="menu-item"><a href="m_bijeong.html">(M.S.)&nbsp;B.&nbsp;I.&nbsp;Jeong</a></div>
<div class="menu-item"><a href="m_jybyeon.html">(M.S.)&nbsp;J.&nbsp;Y.&nbsp;Byeon</a></div>
<div class="menu-item"><a href="m_jkphi.html">(M.S.)&nbsp;J.&nbsp;K.&nbsp;Phi</a></div>
<div class="menu-item"><a href="m_ghjeon.html">(M.S.)&nbsp;G.&nbsp;H.&nbsp;Jeon</a></div>
<div class="menu-item"><a href="m_hjlee.html">(M.S.)&nbsp;H.&nbsp;J.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_jhpark.html">(M.S.)&nbsp;J.&nbsp;H.&nbsp;Park</a></div>
<div class="menu-item"><a href="m_khseong.html">(M.S.)&nbsp;K.&nbsp;H.&nbsp;Seong</a></div>
<div class="menu-item"><a href="m_hskim.html">(M.S.)&nbsp;H.&nbsp;S.&nbsp;Kim</a></div>
<div class="menu-item"><a href="m_jhlee.html">(M.S.)&nbsp;J.&nbsp;H.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_yjlee.html">(B.S.)&nbsp;Y.&nbsp;J.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_mkjeong.html">(B.S.)&nbsp;M.&nbsp;K.&nbsp;Jeong</a></div>
<div class="menu-category">Collaborators</div>
<div class="menu-item"><a href="m_smlee.html">(Prof)&nbsp;S.&nbsp;M.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_shlee.html">(Prof)&nbsp;S.&nbsp;H.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_jskwon.html">(Dr.&nbsp;)&nbsp;J.&nbsp;S.&nbsp;Kwon</a></div>
<div class="menu-item"><a href="m_dklee.html">(Dr.&nbsp;)&nbsp;D.&nbsp;K.&nbsp;Lee</a></div>
<div class="menu-category">Contact</div>
<div class="menu-item"><a href="contact.html">KNU-Location</a></div>
<div class="menu-category">2025 Visit Count<script type=text/javascript src=https://www.freevisitorcounters.com/auth.php?id=aed664a85f8e4ef301449cfed4f947df8e641b6f></script><script type=text/javascript src=https://www.freevisitorcounters.com/en/home/counter/1333199/t/1></script></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Heuijee Yun (Integrated Ph.D. Candidate)</h1>
</div>
<table class="imgtable"><tr><td>
<img src="images/hjyoun.jpg" alt="main" width="100px" />&nbsp;</td>
<td align="left"><p>Integrated Ph.D. Candidate.<br /> 
<a href="http://ai-soc.github.io">AI-Embedded System/Software on Chip (AI-SoC) Lab</a><br />
<a href="http://see.knu.ac.kr">School of Electronics Engineering</a><br />
IT-1, no. 724, Kyungpook National University <br />
Daehak-ro 80, Buk-gu, Daegu, Republic of Korea <br /> 
Phone: +82 053 940 8648 <br />
E-mail: <i>sealstar90</i> [@] gmail [DOT] com <br />
[<a href="https://heuijee.github.io/">Homepage</a>] [<a href="https://scholar.google.com/citations?user=i3x5dVoAAAAJ&amp;hl=en">Google Scholar</a>] [<a href="member/hjyoun_cv.pdf">CV</a>] [<a href="svn/hjyoun.html">SVN</a>]</p>
</td></tr></table>
<h2>Repository Commit History </h2>
<table class="imgtable"><tr><td>
<img src="member/hjyoun_svn.jpg" alt="main" width="700px" />&nbsp;</td>
<td align="left"></td></tr></table>
<h2>Introduction</h2>
<h3>Full Bio Sketch </h3>
<p>Ms. Yun received her B.S. Degree in Electronics Engineering at Kyungpook National University, Daegu, Korea in 2022. She is currently an Integrated Ph.D. student in School of Electronic and Electrical Engineering at Kyungpook National University, Daegu, Republic of Korea. Her research interests include image processing that can be implemented on a lightweight embedded board. Also, she has been conducting various simulations and light-weight image processing required for autonomous driving using deep learning and parallel processing of FPGA. She is currently researching about algorithm of low-power for image processing in an autonomous driving ADAS system. She received 2024 KNU-EE Funded Excellence Ph.D Award (<font color=red>10,000,000 Won</font> Scholarship). She received excellent research grant (<font color=red>25,000,000 Won</font> Scholarship) from National Research Foundation (NRF) in 2025.</p>
<h2>Research Topic</h2>
<h3>LiDAR Signal Processing</h3>
<p><img src=member/hjyoun_topic1.jpg align=right width=500> Among the functions of self-driving cars, avoidance after object recognition is important. Because camera data alone is insufficient to recognize and avoid people or obstacles, we train objects as deep neural networks with data combined with LiDAR data. Then we can apply the educated weight using Yolo, Tensorflow and Opencv for object detection. As a result, Obstacle avoidance algorithms can be executed more accurately and faster.</p>
<h3>FPGA-based Oject Detection for Autonomous Driving</h3>
<p><img src=member/hjyoun_topic2.jpg align=right width=500> Parallelization of image processing for low-power implement - Currently, the board used for autonomous driving is equivalent to a single computer. While various studies are being conducted in the direction of using lightweight FPGAs for efficiency, we study data of image sensors, which are essential functions for ADAS systems in autonomous vehicles. When a huge amount of image data is input, a lightweight algorithm is studied so that the data can be used in a lightweight FPGA. The lane recognition algorithm is largely composed of two flows, canny edge detection and hough transform. At this time, canny edge detection passes through several filters, and at this time, many matrix operations must use several resources. We parallelized this task on a pixel basis and implemented it using a hardware language with low power, small runtime, and constant accuracy. </p>
<p>Currently, with the active development of autonomous driving, several technologies corresponding to it are developing. An essential technology to achieve a high level of autonomous driving is image processing technology. Since the camera input is an essential element, the key is how to implement it in a lightweight vehicle processor. Therefore, we study a lightweight image processing method using parallel processing so that it can be executed on a lightweight embedded board. There are two major algorithms required for lane recognition: Canny edge detection and Hough transformation. Hough transformation cannot be parallelized because all pixels must be read due to the nature of the algorithm, and Canny edge detection is parallelized. After completing the grayscale conversion, the gaussian smoothing, sobel operator, non-maximum suppression and hysteresis parts can be parallelized. Since this part requires filter operation, the corresponding pixel must be determined and parallelized. The pixels in each thread must be at least 5 wide because the Gaussian filter is 5x5. Through this parallelization, efficient results can be obtained in terms of memory and time, and accordingly, a lightweight lane recognition algorithm can be implemented</p>
<h3>On-Chip Instruction Execution Acceleration for AI Processors</h3>
<p><img src=member/hjyoun_topic3.jpg align=right width=500> Recently, it has become possible to train neural networks on MPUs to achieve high performance and reduce power consumption. However, analyzing and processing the massive amounts of data used in deep learning is only being done on better performing multicore microprocessors. ARM-based cores have introduced the concept of single instruction, multiple data (SIMD), which plays an important role in optimizing the performance of deep learning algorithms. SIMD is a parallel processing technique classified according to Flynn's taxonomy. However, SIMD is only available on certain ARM cores and compilers, and it increases the size of the bus because it sends and receives 128-bit data. It also requires vectorization of the input data, which requires resources for preprocessing. Therefore, we introduce an implementation of micro-SIMD on the ARM Cortex M0 structure. Although the original ARM Cortex M0 does not have a SIMD, we generated and executed 16-bit instructions directly. Neural network training algorithms such as CNNs require a huge number of loops and MAC operations for each training layer. The parallelism of micro-SIMD can be very effective in computations like this, where the same operations are performed repeatedly.</p>
<h3>Deep Learning based Human Detection using Thermal-RGB Data Fusion </h3>
<p><img src=member/hjyoun_topic4.jpg align=right width=500> As the number of drivers increases every year, so does the number of traffic fatalities. In Korea, pedestrian accidents accounted for 35.5% of all traffic accidents in the last two years, and the number of accidents involving children is increasing every year. Currently, self-driving cars rely on lidar, which can only recognize obstacles in the distance, making it inadequate for accident prevention. To reduce these accidents, we propose selective thermal data that can identify people beyond the limited field of view. We first utilize RGB camera image data for object recognition. In the presence of vehicles or obstacles, we selectively use thermal data. The thermal data can only identify people, which is used to prevent unexpected accidents. The RGB image is divided into thirds and each section is evaluated for obstacles, prioritizing the areas with the most obstacles for integration with thermal data. Using the algorithm described, the accuracy increased by a factor of 2.07, from 40.43% to 83.91%. In addition, experiments performed on a personal computer show that the algorithm can operate in real time at a rate of 2.7 frames per second, using 175.95 megabytes of memory for 0.36 seconds per image. When running the algorithm on a lightweight board such as the Jetson Nano, it runs at a rate of 0.75 frames per second, using 140.08 megabytes of memory for 1.33 seconds per image.</p>
<h3>Spike Neural Network SoC Implementation</h3>
<p><img src=member/hjyoun_topic5.jpg align=right width=500> SNNs are a type of artificial neural network (ANN) that mimic the way brain neural networks process information. They use spikes as the unit of information, which propagate through a network of neurons and synapses. Spikes exchange only discrete information about whether a spike occurred in a specific neuron at a specific time, as opposed to tensors or floats in existing deep learning networks such as MLP, RNN, and CNN. The Convolutional Spiking Neural Network structure can operate with fewer electrical signals and is more energy efficient than deep neural networks (DNN) and convolutional neural networks (CNN) because it consumes less power. However, this comes at the cost of lower accuracy. To address this issue, we propose a structure that computes multiple Convolutional layers in parallel by classifying them according to the patterns in the input dataset. This structure creates parallel layers based on the input class and prunes the processing element (PE) units to fit each input. The resulting structure is more accurate and can be trained on lightweight hardware. </p>
<h3>Hardware Accelerator for Spiking Self-Supervised Learning</h3>
<p><img src=member/hjyoun_topic6.jpg align=right width=400> Conventional self-supervised learning (SSL) models have demonstrated significant potential for efficiently learning from large-scale unstructured data. However, their high computational complexity and resource demands pose challenges for deployment on edge devices or hardware-constrained environments. In contrast, Spiking Neural Networks (SNNs), inspired by biological neurons, are characterized by low power consumption and asynchronous processing, making them highly efficient in resource-limited settings. Despite these advantages, no hardware accelerator currently exists that combines SSL models with SNNs, and research on optimization techniques integrating these two technologies remains insufficient. Therefore, we propose a high-performance hardware accelerator architecture for spiking SSL models along with corresponding hardware optimization methods. This architecture leverages the unique characteristics of both SNNs and SSL to maximize computational efficiency through data preprocessing, memory optimization, parallel processing, and pipelined structures.</p>
<h3>Loop Structured RTL Synthesis Framework for Irregular Neural Accelerator  </h3>
<p><img src=member/hjyoun_topic7.jpg align=right width=400> Modern neural networks increasingly exhibit irregular behaviors?such as structural imbalance from skip connections and asymmetric kernels, temporal sparsity from spiking activity or dynamic gating, and conditional irregularity from input dependent routing?which, while improving algorithmic efficiency, make hardware implementation unpredictable and inefficient. Conventional template based flows lock architectural patterns and resource mappings at design time, preventing any adaptation to backend synthesis feedback on timing, power, or area, and thus fail to cope with runtime variability and pipeline stalls. To overcome this rigidity, FLEXOR introduces a closed loop RTL co design framework that begins with model parsing and frontend optimization, where graph level irregularity profiling, pruning, scheduling, operator fusion, and quantization are applied to extract metrics that capture structural, temporal, and conditional irregularities. These metrics then guide a backend loop composed of tuning, RTL code generation, design estimation, and synthesis feedback, where parameterized hardware templates and automated glue code enable iterative refinement. The loop continues until convergence, dynamically adapting architecture and resource allocation to satisfy constraints. Through this integration of irregularity aware profiling and synthesis guided feedback, FLEXOR achieves up to 543.5 percent throughput improvement, preserves up to 90 percent sparsity with negligible accuracy loss, and reduces energy delay product by 52.4 percent, demonstrating a scalable and adaptive solution that breaks the limitations of static template based design flows.</p>
<h3>Dynamic Behavioral Partitioning for Adaptive Task Specific Parallel Neural Network Training</h3>
<p><img src=member/hjyoun_topic8.jpg align=right width=400> The rapid growth of deep learning models in vision, language, and generative AI has amplified the demand for distributed and parallel training, but conventional approaches that statically partition data or models fail to account for dynamic neuron activation patterns, leading to workload imbalance, bottlenecks, and inefficiency in heterogeneous systems. To address these limitations, BPATH introduces a behavior driven framework that analyzes neuron activations, gradients, and computational intensity in real time to derive behavioral metrics. These metrics are processed by a multi stage architecture: the behavioral analysis module extracts activation and gradient statistics; the data clustering engine organizes inputs based on behavioral similarity using methods such as game theoretic clustering, random projection, and ensemble refinement; and the dynamic path design module allocates tasks asynchronously across heterogeneous resources while the resource optimization engine continuously balances workload, adapts to network delays, and mitigates node failures. This integrated structure allows BPATH to create adaptive training paths that reflect both data behavior and system conditions. Experimental evaluation on benchmarks such as COCO and GLUE, using models like ResNet, YOLO, EfficientNet, BERT, and GPT, shows that BPATH improves training speed by up to 91 percent, reduces CPU and GPU memory usage by 94 percent, lowers network latency by 35.2 percent, and enhances adaptation speed to environmental changes by 29.2 percent, demonstrating its ability to significantly boost efficiency, scalability, and resilience in distributed learning</p>
<h2>Publications</h2>
<h3>Journal Publications (<font color=red>SCI</font> 7, <font color=blue>KCI</font> 3)</h3>
<ul>
<li><p>Heuijee Yun and Daejin Park. <b>Virtualization of Self-Driving Algorithms by Interoperating Embedded Controllers on Game Engine for Digital Twining Autonomous Vehicle (<font color=red>SCI</font>)</b> Electronics, 2021.</p>
</li>
<li><p>Heuijee Yun and Daejin Park. <b>Efficient Object Recognition by Masking Semantic Pixel Difference Region of Vision Snapshot for Lightweight Embedded Systems (<font color=blue>KCI</font>)</b> Journal of the Korea Institute of Information and Communication Engineering, 26(6):813-826, 2022.</p>
</li>
<li><p>Heuijee Yun and Daejin Park. <b>Efficient Object Detection based on Masking Semantic Segmentation Region for Lightweight Embedded Processors (<font color=red>SCI</font>)</b> Sensors, 22(22):8890-8911, 2022.</p>
</li>
<li><p>Heuijee Yun and Daejin Park. <b>Low-Power Lane Detection Unit with Sliding-based Parallel Segment Detection Accelerator for Lightweighted Automotive Microcontrollers (<font color=red>SCI</font>)</b> IEEE Access, 12:4339-4353, 2024.</p>
</li>
<li><p>Heuijee Yun and Daejin Park. <b>High-Speed Energy-Efficient Model based Dynamic Pruning using Pattern-based Alignment for Convolutional Spiking Neural Network Hardware Accelerators (<font color=blue>KCI</font>)</b> IEMEK Journal of Embedded Systems and Applications, 2024. </p>
</li>
<li><p>Heuijee Yun and Daejin Park. <b>S3A-NPU: A High-Performance Hardware Accelerator for Spiking Self-Supervised Learning with Dynamic Adaptive Memory Optimization (<font color=red><b>VLSI Top Flagship Journal</b></font>, <font color=red>SCI</font>)</b> IEEE Transactions on Very Large Scale Integration (VLSI) Systems, 33(7):1886-1898, 2025. </p>
</li>
<li><p>Heuijee Yun and Daejin Park. <b>FLEXOR: Breaking Template Walls with Loop-Structured RTL Synthesis Framework for Irregular Neural Accelerators (<font color=red><b>VLSI Top Flagship Journal</b></font>, <font color=red>SCI</font>) (Under Review)</b> IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), 2025.</p>
</li>
<li><p>Heuijee Youn and Daejin Park. <b>B-PATH: Dynamic Behavioral Partitioning for Adaptive Task-Specific Parallel Neural Network Training (<font color=red>SCI</font>) (On Writing)</b> IEEE Transactions on Parallel and Distributed Systems (TPDS), 2025.</p>
</li>
<li><p>Heuijee Youn and Daejin Park. <b>SOAL: Self-Optimizing Edge AI for Autonomous Vehicles with Real-Time Adaptive Learning (<font color=red><b>JCR 2% Top</b></font> Journal,<font color=red>SCI</font>) (On Writing)</b> IEEE Transactions on Intelligent Transportation Systems (TITS), 2025.</p>
</li>
<li><p>Heuijee Yun and Daejin Park. <b>On Preparation (<font color=blue>KCI</font>)</b> Journal of the Korea Institute of Information and Communication Engineering, 2025.</p>
</li>
</ul>
<h3>Conference Publications (Intl. 11)</h3>
<ul>
<li><p>Heuijee Yun and Daejin Park. <b>Simulation of Self-driving System by implementing Digital Twin with GTA5</b> In IEEE ICEIC 2021, 2021.</p>
</li>
<li><p>Heuijee Yun and Daejin Park. <b>Yolo-based Realtime Object Detection using Interleaved Redirection of Time-Multiplxed Streamline of Vision Snapshot for Lightweighted Embedded Processors</b> In 2021 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS), 2021.</p>
</li>
<li><p>Heuijee Yun and Daejin Park. <b>Mitigating Overflow of Object Detection Tasks Based on Masking Semantic Difference Region of Vision Snapshot for High Efficiency</b> In 2022 IEEE International Conference on Artificial Intelligence in Information and Communication (ICAIIC), 2022.</p>
</li>
<li><p>Heuijee Yun and Daejin Park. <b>FPGA Realization of Lane Detection Unit using Sliding-based Parallel Segment Detection for Buffer Memory Reduction</b> In IEEE ICCE 2023, 2023.</p>
</li>
<li><p>Heuijee Yun and Daejin Park. <b>Low-Power Parallel Lane Detection Unit for Lightweight Automotive Processors</b> In IEEE COOLChips 2023, 2023.</p>
</li>
<li><p>Jisu Kwon, Heuijee Yun, and Daejin Park. <b>Dynamic MAC Unit Pruning Techniques in Runtime RTL Simulation for Area-Accuracy Efficient Implementation of Neural Network Accelerator</b> In IEEE MWSCAS 2023, 2023.</p>
</li>
<li><p>Heuijee Yun and Daejin Park. <b>Parallel Processing of 3D Object Recognition by Fusion of 2D Images and LiDAR for Autonomous Driving</b> In International Conference on Electronics, Information, and Communication (ICEIC 2024), 2024.</p>
</li>
<li><p>Heuijee Yun and Daejin Park. <b>Deep Learning based Human Detection using Thermal-RGB Data Fusion for Safe Automotive Guided-Driving</b> In IEEE International Conference on Pervasive Computing and Communication (<font color=red><b>Top Tier Conf. </b></font><font color=blue><b>Percom</b></font> 2024 - Pervehicle), 2024.</p>
</li>
<li><p>Heuijee Yun and Daejin Park. <b>A Power-Efficient Reconfigurable Hybrid CNN-SNN Accelerator for High Performance AI Applications</b> In IEEE Symposium on Low-Power and High-Speed Chips and Systems (<font color=red><b>Flagship Conf. </b></font><font color=blue><b>COOLChips</b></font> 2025), 2025.</p>
</li>
<li><p>Heuijee Yun and Daejin Park. <b>Opti-SpiSSL: A Highly Reconfigurable Hardware Generation Framework for Spiking Self-Supervised Learning on Heterogeneous SoC</b> In IEEE Design Automation Conference (<font color=red><b>Top Tier Conf. </b></font><font color=blue><b>DAC</b></font> 2025), 2025.</p>
</li>
<li><p>Heuijee Yun and Daejin Park. <b>Under Blind Review</b> In IEEE Design, Automation and Test in Europe Conference (DATE 2026) (Under Review), 2026.</p>
</li>
</ul>
<h3>Patents (Total 7 Patents)</h3>
<ul>
<li><p><b>Autonomous Driving Algorithm Simulation Method and System based on Game Engine</b> In Korea Patent and Tradmark Office, Korea Patent 10-260183, 2024  </p>
</li>
<li><p><b>Real-Time Object Detection System and Method using Interleaving of Snapshots</b> In Korea Patent and Tradmark Office, June 2022. Korea Patent Pending</p>
</li>
<li><p><b>System and Method for Recognizing Object Included in Image</b> In Korea Patent and Tradmark Office, June 2022. Korea Patent Pending</p>
</li>
<li><p><b>Compiling Device and Method for Spiking Neural Network Model</b> In Korea Patent and Tradmark Office, Dec 2024. Korea Patent Pending</p>
</li>
<li><p><b>Accelerator for Spiking Self-Supervised Learning Model and Computational Method of the Accelerator</b> In Korea Patent and Tradmark Office, Dec 2024. Korea Patent Pending</p>
</li>
<li><p><b>FPGA-based Lane Detection Accelerator and Lane Detection Method</b> In Korea Patent and Tradmark Office, Dec 2024. Korea Patent Pending</p>
</li>
<li><p><b>Pedestrian Detection Method and Pedestrian Detection Device Performing the Same</b> In Korea Patent and Tradmark Office, Dec 2024. Korea Patent Pending</p>
</li>
</ul>
<h3>Participation in International Conference</h3>
<ul>
<li><p>IEEE ICEIC 2021, Jeju, Korea</p>
</li>
<li><p>IEEE ISPACS 2021, Jeju, Korea</p>
</li>
<li><p>IEEE ICAIIC 2022, Jeju, Korea</p>
</li>
<li><p>ACM Micro 2022, Chicago, USA</p>
</li>
<li><p>ACM Multimedia ASIA 2022, Tokyo, Japan</p>
</li>
<li><p>IEEE ICCE 2023, Las Vegas, USA</p>
</li>
<li><p>IEEE COOLChips 2023, Tokyo, Japan</p>
</li>
<li><p>IEEE MWSCAS 2023, Arizona, USA</p>
</li>
<li><p>IEEE ICEIC 2024, Taipei, Taiwan</p>
</li>
<li><p>IEEE Percom 2024, Biarritz, France</p>
</li>
<li><p>IEEE ISLPED 2024, California, USA</p>
</li>
<li><p>IEEE COOLChips 2025, Tokyo, Japan</p>
</li>
<li><p>IEEE DAC 2025, San Francisco, USA</p>
</li>
</ul>
<p>Last Updated, 2025.09.09</p>
<div id="footer">
<div id="footer-text">This page was generated by our compiler @ copyright reserved (AI-S<sup><font size=1>2</font></sup>oC Lab<img src=images/logo.jpg width=20 >)
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
