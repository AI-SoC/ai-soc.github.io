<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Titillium Web">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="script/aisoc.css" type="text/css" />
<title>Sunghoon Hong (Ph.D. Candidate, SYSCON Robotics)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">AI-S<sup><font size=1>2</font></sup>oC Lab<img src=images/logo.jpg width=20 ></div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="l_professor.html">Professor</a></div>
<div class="menu-item"><a href="l_members.html">Members</a></div>
<div class="menu-item"><a href="l_interns.html">Candidates</a></div>
<div class="menu-item"><a href="l_alumni.html">Alumni</a></div>
<div class="menu-item"><a href="l_research.html">Research</a></div>
<div class="menu-item"><a href="l_equipment.html">Equipment</a></div>
<div class="menu-item"><a href="l_symposium.html">Symposium</a></div>
<div class="menu-item"><a href="l_tutorials.html">Tutorials</a></div>
<div class="menu-item"><a href="l_photos.html">Photos</a></div>
<div class="menu-category">For Candidates</div>
<div class="menu-item"><a href="s_courses.html">Preparation</a></div>
<div class="menu-item"><a href="l_benefit.html">Benefit</a></div>
<div class="menu-item"><a href="s_contact.html">Contact</a></div>
<div class="menu-category">Publication</div>
<div class="menu-item"><a href="l_journals.html">Journals</a></div>
<div class="menu-item"><a href="l_conferences.html">Conferences</a></div>
<div class="menu-item"><a href="l_presentation.html">Presentations</a></div>
<div class="menu-item"><a href="l_mybooks.html">Authored&nbsp;Books</a></div>
<div class="menu-item"><a href="l_patents.html">Patents</a></div>
<div class="menu-category">Teaching</div>
<div class="menu-item"><a href="l_courses.html">Courses</a></div>
<div class="menu-item"><a href="l_study.html">Study</a></div>
<div class="menu-item"><a href="c_lpsoc.html">Low&nbsp;Power&nbsp;SoC</a></div>
<div class="menu-item"><a href="c_cprog.html">C&nbsp;Programming</a></div>
<div class="menu-item"><a href="c_dsp.html">DSP</a></div>
<div class="menu-category">Useful Data</div>
<div class="menu-item"><a href="u_software.html">Software</a></div>
<div class="menu-item"><a href="u_must_books.html">Must-Read&nbsp;Books</a></div>
<div class="menu-category">Member Profile (24)</div>
<div class="menu-item"><a href="m_smlee.html">(Prof)&nbsp;S.&nbsp;M.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_jskwon.html">(Ph.D)&nbsp;J.&nbsp;S.&nbsp;Kwon</a></div>
<div class="menu-item"><a href="m_mjkang.html">(Ph.D)&nbsp;M.&nbsp;J.&nbsp;Kang</a></div>
<div class="menu-item"><a href="m_shhong.html" class="current">(Ph.D)&nbsp;S.&nbsp;H.&nbsp;Hong</a></div>
<div class="menu-item"><a href="m_shcho.html">(Ph.D)&nbsp;S.&nbsp;H.&nbsp;Cho</a></div>
<div class="menu-item"><a href="m_jhan.html">(Ph.D)&nbsp;J.&nbsp;H.&nbsp;An</a></div>
<div class="menu-item"><a href="m_shwlee.html">(Ph.D)&nbsp;S.&nbsp;H.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_hjyoun.html">(Ph.D)&nbsp;H.&nbsp;J.&nbsp;Yun</a></div>
<div class="menu-item"><a href="m_yhlee.html">(Ph.D)&nbsp;Y.&nbsp;H.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_shpark.html">(Ph.D)&nbsp;S.&nbsp;H.&nbsp;Park</a></div>
<div class="menu-item"><a href="m_mjkim.html">(M.S.)&nbsp;M.&nbsp;J.&nbsp;Kim</a></div>
<div class="menu-item"><a href="m_bijeong.html">(M.S.)&nbsp;B.&nbsp;I.&nbsp;Jeong</a></div>
<div class="menu-item"><a href="m_jybyeon.html">(M.S.)&nbsp;J.&nbsp;Y.&nbsp;Byeon</a></div>
<div class="menu-item"><a href="m_jkphi.html">(M.S.)&nbsp;J.&nbsp;K.&nbsp;Phi</a></div>
<div class="menu-item"><a href="m_ghjeon.html">(M.S.)&nbsp;G.&nbsp;H.&nbsp;Jeon</a></div>
<div class="menu-item"><a href="m_hjlee.html">(M.S.)&nbsp;H.&nbsp;J.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_jhpark.html">(M.S.)&nbsp;J.&nbsp;H.&nbsp;Park</a></div>
<div class="menu-item"><a href="m_khseong.html">(M.S.)&nbsp;K.&nbsp;H.&nbsp;Seong</a></div>
<div class="menu-item"><a href="m_jhlee.html">(B.S.)&nbsp;J.&nbsp;H.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_hskim.html">(B.S.)&nbsp;H.&nbsp;S.&nbsp;Kim</a></div>
<div class="menu-item"><a href="m_jylee.html">(B.S.)&nbsp;J.&nbsp;Y.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_yjlee.html">(B.S.)&nbsp;Y.&nbsp;J.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_mkjeong.html">(B.S.)&nbsp;M.&nbsp;K.&nbsp;Jeong</a></div>
<div class="menu-category">Collaborators</div>
<div class="menu-item"><a href="m_shlee.html">(Prof)&nbsp;S.&nbsp;H.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_dklee.html">(Dr.&nbsp;)&nbsp;D.&nbsp;K.&nbsp;Lee</a></div>
<div class="menu-category">Contact</div>
<div class="menu-item"><a href="contact.html">KNU-Location</a></div>
<div class="menu-category">2025 Visit Count<script type=text/javascript src=https://www.freevisitorcounters.com/auth.php?id=aed664a85f8e4ef301449cfed4f947df8e641b6f></script><script type=text/javascript src=https://www.freevisitorcounters.com/en/home/counter/1333199/t/1></script></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Sunghoon Hong (Ph.D. Candidate, SYSCON Robotics)</h1>
</div>
<table class="imgtable"><tr><td>
<img src="images/shhong_profile.jpg" alt="main" width="200px" />&nbsp;</td>
<td align="left"><p>Ph.D. Prospective Candidate<br /> 
<a href="http://ai-soc.github.io">AI-Embedded System/Software on Chip (AI-SoC) Platform Lab</a><br />
<a href="http://see.knu.ac.kr">School of Electronics Engineering</a><br />
IT-1, no. 724, Kyungpook National University <br />
Daehak-ro 80, Buk-gu, Daegu, Republic of Korea <br /> 
Phone: +82 053 940 8648 <br />
E-mail: <i>hopsison</i> [@] gmail [DOT] com <br />
[<a href="https://sites.google.com/view/sunghoonhong">Homepage</a>] [<a href="https://scholar.google.com/citations?user=lWeYPg8AAAAJ&amp;hl=en">Google Scholar</a>] [<a href="svn/shhong.html">SVN</a>] [<a href="member/shhong_cv.pdf">CV</a>]</p>
</td></tr></table>
<h2>Repository Commit History </h2>
<table class="imgtable"><tr><td>
<img src="member/shhong_svn.jpg" alt="main" width="700px" />&nbsp;</td>
<td align="left"></td></tr></table>
<h2>Introduction</h2>
<h3>Full Bio Sketch </h3>
<p>Sunghoon Hong (Ph.D. Course) received the M.S. degree in Intelligent Robot Engineering at Hanyang University, Seoul, Korea, in 2016. His main interest is Human-Like Autonomous Driving Systems. He has a lot of experience in autonomous driving technologies such as SLAM (Simultaneous Localization And Mapping), ADAS (Advanced Driver Assistance Systems), PID (Proportional-Integral-Differential) control, machine learning, path-planning and navigation algorithms and has published several journal/conference papers. Currently, He was a research engineer at Carnavicom.Co., Ltd. from 2021 and Department of Electronics, Kyungpook National University, Daegu, Korea from 2021. He is researching technologies to optimize deep learning-based object detection algorithms for human-like artificial intelligence autonomous driving systems to be applied to low-power embedded systems.</p>
<h2>Research Topic</h2>
<p>Eyes are the most important factor for a person to drive a vehicle. Human-like autonomous driving systems use camera sensors to recognize vehicles, bicycles, people, lanes, roads, signs, traffic lights, etc. through deep learning technology. This information helps estimate the vehicle's current location and drive autonomously along its global path to its final destination. However, there is a limit to directly applying deep learning technology to embedded systems, algorithm optimization techniques are required. In this way, I would like to intensively research optimization techniques to develop vision-based human-like autonomous driving technologies in real-time low power embedded systems.</p>
<h3>Runtime ML-DL Hybrid Inference Platform Based on Multiplexing Adaptive Space-Time Resolution for Fast Car Incident Prevention in Low-Power Embedded Systems</h3>
<p><img src=member/shhong_topic1.jpg width=700> Forward vehicle detection is the key technique to preventing car incident in front. Artificial intelligence (AI) techniques are used to more accurately detect vehicles, but AI-based vehicle detection takes a lot of processing time due to its high computational complexity. When there is a risk of collision with a vehicle in front, the slow detection speed of the vehicle may lead to an accident. To quickly detect a vehicle in real-time, a high-speed and lightweight vehicle detection technique with similar detection performance to that of an existing AI-based vehicle detection is required. Also, to apply forward collision warning system (FCWS) technology to vehicles, it is important to provide high performance based on low-power embedded systems because the vehicleâ€™s battery consumption must remain low. The vehicle detection algorithm occupies the most resources in FCWS. To reduce power consumption, it is important to reduce the computational complexity of an algorithm, that is, the amount of resources required to run it. This paper describes a method for fast, accurate forward vehicle detection using machine learning and deep learning. To detect a vehicle in consecutive images consistently, a Kalman filter is used to predict the bounding box based on the tracking algorithm and correct it based on the detection algorithm. As a result, its vehicle detection speed is about 25.85 times faster than deep-learning-based object detection is, and its detection accuracy is better than machine-learning-based object detection is. </p>
<h3>Continuous Differential Image-based Fast Convolution for Convolutional Neural Networks</h3>
<p><img src=member/shhong_topic2.png width=700> Convolutional neural networks with powerful visual image analysis of deep structures are gaining popularity in many research fields. The main difference in convolutional neural networks compared to other artificial neural networks is the addition of many convolutional layers. The convolutional layer improves the performance of artificial neural networks by extracting feature maps required for image classification. However, for applications that require very low-latency on limited processing resources, the success of a convolutional neural network depends on how fast we can compute. In this paper, we propose a novel convolution technique of fast algorithms for convolutional neural networks using continuous differential images. The proposed method improves the response speed of the algorithm by reducing the computational complexity of the convolutional layer. It is compatible with all types of convolutional neural networks, and the lower the difference in the continuous images, the better the performance. We use the darknet network to benchmark the CPU implementation of our algorithm and show state-of-the-art throughput at pixel difference thresholds from 0 to 25 pixels. </p>
<h3>Differential Image-based Fast and Compatible Convolutional Layers for Multi-core Processors</h3>
<p><img src=member/shhong_topic3.png width=700> Convolutional neural networks with powerful visual image analysis for artificial intelligence are gaining popularity in many research fields, leading to the development of various high-performance algorithms for convolution operators present in these networks. One of these approaches is implemented with general matrix multiplication (GEMM) using the well-known im2col transform for fast convolution operations. In this paper, we propose a multi-core processor-based convolution technique for high-speed convolutional neural networks (CNNs) using differential images. The proposed method improves the convolutional layer response speed by reducing the computational complexity and using multi-thread technology. In addition, the proposed algorithm has the advantage of being compatible with all types of CNNs. We use the darknet network to evaluate the convolutional layer's performance and show the best performance of the proposed algorithm when using 4-thread parallel processing.</p>
<h3>Differential Image-based Scalable YOLOv7-Tiny Implementation for Clustered Embedded Systems</h3>
<p><img src=member/shhong_topic4.jpg width=700> Convolutional neural networks (CNNs) for powerful visual image analysis are gaining popularity in artificial intelligence. The main difference in CNNs compared to other artificial neural networks is that many convolutional layers are added, which improve the performance of visual image analysis by extracting the feature maps required for image classification. However, algorithm optimization is required to run applications that require low-latency in edge compute modules with limited processing resources. In this paper, we propose a novel algorithm optimization method for fast CNNs by using continuous differential images. The main idea is to reduce computation variably by using the differential value of the input in each convolutional layer. Also, the proposed method is compatible with all types of CNNs, and the performance is better when the pixel value difference of continuous images is low. We use the DarkNet framework to evaluate our algorithm using fast convolution and half convolution approaches on a clustered system. As a result, when the input frame rate is 10 fps, FLOPs are reduced by about 4.92 times compared to the original YOLOv7-tiny. By reducing the FLOPs of the convolutional layer, the inference speed increases to about 4.86 FPS, performing 1.57 times faster than the original YOLOv7-tiny. In the case of parallel processing that used two edge compute modules for using half convolution approach, FLOPs reduced more, and the response speed improved. In addition, faster Object detection implementation is possible by additionally expanding up to 7 compute modules in a scalable clustered embedded system as much as the user wants.</p>
<h2>Publications</h2>
<h3>Journal Publications (<font color=blue>KCI</font> 2, <font color=red>SCI</font> 5)</h3>
<ul>
<li><p>Sunghoon Hong and Daejin Park. <b>Vision-based Real-time Vehicle Detection and Tracking Algorithm for Forward Collision Warning (<font color=blue>KCI</font>)</b> Journal of the Korea Institute of Information and Communication Engineering, 25(7):962-970, 2021.</p>
</li>
<li><p>Sunghoon Hong and Daejin Park. <b>Lane Detection Based on Inverse Perspective Transformation and Machine Learning in Lightweight Embedded System (<font color=blue>KCI</font>)</b> IEMEK Journal of Embedded Systems and Applications, 2022.</p>
</li>
<li><p>Sunghoon Hong and Daejin Park. <b>Runtime ML-DL Hybrid Inference Platform based on Multiplexing Adaptive Space-Time Resolution for Lightweight Object Detection in Low-Power Embedded Systems (<font color=red>SCI</font>)</b> Sensors, 22(8):2998-3011, 2022.</p>
</li>
<li><p>Sunghoon Hong and Daejin Park. <b>On-Chip Realization of Efficient Lane Departure Warning Systems using Inverse Perspective Transformation and Machine Learning-based Lane Prediction (<font color=red>SCI</font>)</b> IEEE Transactions on Intelligent Transportation Systems, 2023.</p>
</li>
<li><p>Sunghoon Hong and Daejin Park. <b>ML-based Fast and Precise Embedded Rack Detection Software for Docking and Transport of Autonomous Mobile Robots using 2-D LiDAR (<font color=red>SCI</font>)</b> IEEE Embedded Systems Letters, 16(4):401-404, 2024.  </p>
</li>
<li><p>Sunghoon Hong and Daejin Park. <b>ML-based Fast and Precise Target Docking of Autonomous Mobile Robots for Intelligent Transportation Systems using 2D LiDAR (<font color=red>SCI</font>) </b> IEEE Transactions on Intelligent Transportation Systems, 2024.</p>
</li>
<li><p>Sunghoon Hong and Daejin Park. <b>On-Chip Realization of Efficient Lane Departure Warning Systems using Inverse Perspective Transformation and Machine Learning-based Lane Detection (<font color=red>SCI</font>) (On Writing)</b> IEEE Transactions on Vehicular Technology, 2024.</p>
</li>
</ul>
<h3>Conference Publications (Intl. 5)</h3>
<ul>
<li><p>Seunghoon Hong and Daejin Park. <b>Lightweight Collaboration of Detecting and Tracking Algorithm in Low-Power Embedded Systems for Forward Collision Warning</b> In IEEE ICUFN 2021, 2021.</p>
</li>
<li><p>Sunghoon Hong and Daejin Park. <b>Runtime Virtual Lane Prediction Based on Inverse Perspective Transformation and Machine Learning for Lane Departure Warning in Low-Power Embedded Systems</b> In IEEE IST 2022, 2022.</p>
</li>
<li><p>Sunghoon Hong and Daejin Park. <b>Continuous Image-based Fast Convolution for Convolutional Neural Network</b> In IEEE ICTC 2022, 2022.</p>
</li>
<li><p>Sunghoon Hong and Daejin Park. <b>Differential Image-based Fast and Compatible Convolutional Layers for Multicore Processors</b> In IEEE ICAIIC 2023, 2023.</p>
</li>
<li><p>Sunghoon Hong and Daejin Park. <b>ML-based Fast and Precise Embedded Rack Detection Software for Docking and Transport of Autonomous Mobile Robots using 2D LiDAR</b> In IEEE International Conference on Embeeded Software (EMSOFT 2024), (Recommended to IEEE Embedded Systems Letters), 2024.</p>
</li>
</ul>
<h3>Patents (Domestic 1)</h3>
<ul>
<li><p><b>Object Detection Method and Object Detection Device Performing the Same</b> In Korea Patent and Tradmark Office, June 2022. Korea Patent Pending</p>
</li>
</ul>
<h3>Participation in International Conference</h3>
<ul>
<li><p>IEEE ICUFN 2021, Jeju, Korea</p>
</li>
<li><p>IEEE IST 2022, Virtual</p>
</li>
<li><p>IEEE ICTC 2022, Jeju, Korea</p>
</li>
<li><p>IEEE ICAIIC 2023, Bali, Indonnesia</p>
</li>
<li><p>IEEE EMSOFT 2024, RALEIGH, NC, USA </p>
</li>
</ul>
<h2>Projects</h2>
<ul>
<li><p>UAV 3-D SLAM (Simultaneous Localization And Mapping) using RGB-D and IMU sensors</p>
</li>
<li><p>FCWS (Forward Collision Warning System) using a single camera</p>
</li>
<li><p>Android app development for in-vehicle ADAS device installation</p>
</li>
<li><p>MCU (Micro Controller Unit) development for display and vehicle control</p>
</li>
<li><p>Precision position control using single camera and magnetic sensor for autonomous mobile robot</p>
</li>
<li><p>Marker-based docking using a single camera for autonomous mobile robot</p>
</li>
<li><p>SLAM (Simultaneous Localization And Mapping) using Lidar and RGB-D sensors for autonomous mobile robot</p>
</li>
<li><p>Path-planning and navigation for autonomous mobile robot</p>
</li>
<li><p>Deep learning-based object detection in low power embedded systems</p>
</li>
</ul>
<p>Last Updated, 2025.05.30</p>
<div id="footer">
<div id="footer-text">This page was generated by our compiler @ copyright reserved (AI-S<sup><font size=1>2</font></sup>oC Lab<img src=images/logo.jpg width=20 >)
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
