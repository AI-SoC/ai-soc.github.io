<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Titillium Web">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="script/aisoc.css" type="text/css" />
<title>Hyunjung Lee (M.S. Graduate Student)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">AI-S<sup><font size=1>2</font></sup>oC Lab<img src=images/logo.jpg width=20 ></div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="l_professor.html">Professor</a></div>
<div class="menu-item"><a href="l_members.html">Members</a></div>
<div class="menu-item"><a href="l_interns.html">Candidates</a></div>
<div class="menu-item"><a href="l_alumni.html">Alumni</a></div>
<div class="menu-item"><a href="l_research.html">Research</a></div>
<div class="menu-item"><a href="l_equipment.html">Equipment</a></div>
<div class="menu-item"><a href="l_symposium.html">Symposium</a></div>
<div class="menu-item"><a href="l_tutorials.html">Tutorials</a></div>
<div class="menu-item"><a href="l_photos.html">Photos</a></div>
<div class="menu-category">For Candidates</div>
<div class="menu-item"><a href="s_courses.html">Preparation</a></div>
<div class="menu-item"><a href="l_benefit.html">Benefit</a></div>
<div class="menu-item"><a href="s_contact.html">Contact</a></div>
<div class="menu-category">Publication</div>
<div class="menu-item"><a href="l_journals.html">Journals</a></div>
<div class="menu-item"><a href="l_conferences.html">Conferences</a></div>
<div class="menu-item"><a href="l_presentation.html">Presentations</a></div>
<div class="menu-item"><a href="l_mybooks.html">Authored&nbsp;Books</a></div>
<div class="menu-item"><a href="l_patents.html">Patents</a></div>
<div class="menu-category">Teaching</div>
<div class="menu-item"><a href="l_courses.html">Courses</a></div>
<div class="menu-item"><a href="l_study.html">Study</a></div>
<div class="menu-item"><a href="c_lpsoc.html">Low&nbsp;Power&nbsp;SoC</a></div>
<div class="menu-item"><a href="c_cprog.html">C&nbsp;Programming</a></div>
<div class="menu-item"><a href="c_dsp.html">DSP</a></div>
<div class="menu-category">Useful Data</div>
<div class="menu-item"><a href="u_software.html">Software</a></div>
<div class="menu-item"><a href="u_must_books.html">Must-Read&nbsp;Books</a></div>
<div class="menu-category">Member Profile (20)</div>
<div class="menu-item"><a href="m_shcho.html">(Ph.D)&nbsp;S.&nbsp;H.&nbsp;Cho</a></div>
<div class="menu-item"><a href="m_shhong.html">(Ph.D)&nbsp;S.&nbsp;H.&nbsp;Hong</a></div>
<div class="menu-item"><a href="m_mjkang.html">(Ph.D)&nbsp;M.&nbsp;J.&nbsp;Kang</a></div>
<div class="menu-item"><a href="m_jhan.html">(Ph.D)&nbsp;J.&nbsp;H.&nbsp;An</a></div>
<div class="menu-item"><a href="m_shwlee.html">(Ph.D)&nbsp;S.&nbsp;H.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_hjyoun.html">(Ph.D)&nbsp;H.&nbsp;J.&nbsp;Yun</a></div>
<div class="menu-item"><a href="m_yhlee.html">(Ph.D)&nbsp;Y.&nbsp;H.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_shpark.html">(Ph.D)&nbsp;S.&nbsp;H.&nbsp;Park</a></div>
<div class="menu-item"><a href="m_mjkim.html">(Ph.D)&nbsp;M.&nbsp;J.&nbsp;Kim</a></div>
<div class="menu-item"><a href="m_bijeong.html">(M.S.)&nbsp;B.&nbsp;I.&nbsp;Jeong</a></div>
<div class="menu-item"><a href="m_jybyeon.html">(M.S.)&nbsp;J.&nbsp;Y.&nbsp;Byeon</a></div>
<div class="menu-item"><a href="m_jkphi.html">(M.S.)&nbsp;J.&nbsp;K.&nbsp;Phi</a></div>
<div class="menu-item"><a href="m_ghjeon.html">(M.S.)&nbsp;G.&nbsp;H.&nbsp;Jeon</a></div>
<div class="menu-item"><a href="m_hjlee.html" class="current">(M.S.)&nbsp;H.&nbsp;J.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_jhpark.html">(M.S.)&nbsp;J.&nbsp;H.&nbsp;Park</a></div>
<div class="menu-item"><a href="m_khseong.html">(M.S.)&nbsp;K.&nbsp;H.&nbsp;Seong</a></div>
<div class="menu-item"><a href="m_hskim.html">(M.S.)&nbsp;H.&nbsp;S.&nbsp;Kim</a></div>
<div class="menu-item"><a href="m_jhlee.html">(M.S.)&nbsp;J.&nbsp;H.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_yjlee.html">(B.S.)&nbsp;Y.&nbsp;J.&nbsp;Lee</a></div>
<div class="menu-item"><a href="m_mkjeong.html">(B.S.)&nbsp;M.&nbsp;K.&nbsp;Jeong</a></div>
<div class="menu-category">Contact</div>
<div class="menu-item"><a href="contact.html">KNU-Location</a></div>
<div class="menu-category">2025 Visit Count<script type=text/javascript src=https://www.freevisitorcounters.com/auth.php?id=aed664a85f8e4ef301449cfed4f947df8e641b6f></script><script type=text/javascript src=https://www.freevisitorcounters.com/en/home/counter/1333199/t/1></script></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Hyunjung Lee (M.S. Graduate Student)</h1>
</div>
<table class="imgtable"><tr><td>
<img src="images/hjlee.jpg" alt="main" width="100px" />&nbsp;</td>
<td align="left"><p>Master Graduate Student (M.S), Embedded System-on-Chip Integrator<br /> 
<a href="http://ai-soc.github.io">AI-Embedded System/Software on Chip (AI-SoC) Lab</a><br />
School of Electronics Engineering, Kyungpook National University <br />
Phone: +82 053 940 8648 <br />
E-mail: <i>guswnd0403</i> [@] naver[DOT] com <br /> 
[<a href="https://sites.google.com/knu.ac.kr/lhj0403">Homepage</a>] [<a href="https://scholar.google.co.kr/citations?user=3tUiY_UAAAAJ&amp;hl=ko">Google Scholar</a>] [<a href="svn/hjlee.html">SVN</a>] [<a href="member/hjlee_cv.pdf">CV</a>]</p>
</td></tr></table>
<h2>Repository Commit History </h2>
<table class="imgtable"><tr><td>
<img src="member/hjlee_svn.jpg" alt="main" width="700px" />&nbsp;</td>
<td align="left"></td></tr></table>
<h2>Introduction</h2>
<h3>Full Bio Sketch </h3>
<p>Mr. Lee received his B.S. degree in Electronics Engineering at Kyungpook National University, Daegu, Republic of Korea in 2024. He is currently pursuing toward his M.S. graduate degree in Electronics Engineering at Kyungpook National University, Daegu, Republic of Korea. His research interests cover automotive embedded systems, specially in designing multi-camera interoperable emulation framework using embedded edge-cloud AI computing for autonomous vehicle driving. He is pursuing his research to implement the entire full stacks from low-level embedded firmware to autonomous driving algorithm, including the hardware systems, by interoperating human-interative interfaces.</p>
<h2>Research Topic</h2>
<h3>Vehicle-Controller-Interface Interoperation Emulation Framework</h3>
<p><img src=member/hjlee_topic1.jpg align=right width=300> Frames from four cameras connected to the Raspberry Pi are transmitted to the PC for streaming. On the PC, object detection is performed using yolo based on this streaming screen to determine the location of the object and the distance to the object. Using the identified information, the handling angle and speed for safe driving of the vehicle are appropriately set and transmitted to the Arduino board to ultimately control the vehicle. Additionally, the yoke steering wheel is linked to the PC to transmit the user's current handling angle information. In the process of processing information, control is basically based on the user's current handling angle, and if the angle differs by more than a certain amount from the handling angle for safe driving, not the current handling angle but the handling angle for safe driving is applied to control. Through this, it is possible to respond to various dangerous situations such as lane departure and obstacle collision that can occur when the driver cannot fully concentrate on driving. In driving situations, among the four cameras, information from the front camera is given the highest priority, and information from other cameras is used only in dangerous situations that have exceeded the threshold, allowing the driver to respond to emergency situations.</p>
<p>The distance to an object is defined by converting the coordinates of an object detected in a two-dimensional plane into coordinates in a three-dimensional space based on camera calibration information and measuring the distance from the coordinates where the camera is located. In addition to this method, we are researching various methods of recognizing the distance to an object using a monocular camera, and plan to apply the optimal method.</p>
<h3>Auto Parking Interoperation Emulation Framework</h3>
<p>Additionally, in parking situations, the car is designed to recognize parking lines around the vehicle using four cameras and then automatically park along the optimal parking route by appropriately switching between drive mode and rear mode. The around view, as if looking at the vehicle from above, displays the vehicle when it is parked, allowing the driver to also understand the surrounding situation. Object detection in parking situations raises the standard for risk judgment higher than in driving situations, allowing parking to proceed while safely responding to situations such as when a vehicle or person suddenly passes by while parking.</p>
<h3>3D Mapping </h3>
<p><img src=member/hjlee_topic2.jpg align=right width=300> Using a monocular camera, there is a limitation for applying the algorithms to various situation and reflecting an accurate environment surrounding a vehicle. Therefore, I used stereo camera calibration and stereo vision that can estimate distance from the objects with two cameras (left &amp; right). For 3D mapping, a depth map that reflects the distance from the objects is needed. The depth map can be generated by some functions of the OpenCV, but the provided functions are not good at reflecting real-time. So, I aim to make an own depth map generation model. Each frame is revised to reflect the surrounding frames. By comparing the left and right frames, a depth map can be generated. To elaborate the own depth map, shadows must be removed. The shadows can be removed by mean shift filtering using edges of the screen. By image stitching, the depth maps streaming a front, left, rear and right can be merged so the 3D map that reflects surrounding the vehicle can be generated.</p>
<h3>Adaptive PID Controller </h3>
<p>When autonomous driving, a vehicle can process data from sensing and make decisions to comfort and safe driving. However, this mechanism doesnâ€™t assist or help direct control of the vehicle. Based on the data of surrounding environment, we can adjust the control sensitivity of the vehicle by maintaining the ratio of each gain of PID controller. Therefore, when driving or parking, the vehicle can reach the desired control speed rapidly or slowly than usual based on the spatial data of its own. </p>
<h3>Multithreaded Automotive Controller </h3>
<p><img src=member/hjlee_topic3.jpg align=right width=300> Also, there are a lot of disturbances that can influence the real output of the automotive system. The disturbances make a difference between the desired speed and the real speed, and this can give the driver a sense of incongruity and discomfort. By multithreading, we can prepare an amplified signal, a normal signal, and an attenuated signal in parallel. These signals are applied immediately when the disturbance occurs, and it can reduce the difference and accelerate compensation for the disturbance immediately. Therefore, the drivers can experience comfort driving without any momentary discomfort or sense of incongruity.</p>
<h3>Lightweight RL for Adaptive Super-Twisting Vehicle Control </h3>
<p><img src=member/hjlee_topic4.jpg align=right width=300> The conventional high-performance controller, the Super-Twisting Algorithm (STA), offers excellent stability but lacks the flexibility to adapt to ever-changing driving conditions. Using artificial intelligence like reinforcement learning to solve this is often too computationally intensive and inefficient for real-time operation on a vehicle's embedded computer. Our research proposes a new framework to resolve this dilemma, fusing a lightweight empirical reinforcement learning method that optimizes control parameters in real-time without complex calculations, with a hybrid sliding surface that adaptively blends control behaviors based on the situation.</p>
<p>Through the synergy of these two technologies, the controller exhibits intelligent behavior, reacting quickly and aggressively to large errors while operating smoothly and stably when fine adjustments are needed. Consequently, we implemented an efficient control system that delivers both high performance and smooth responsiveness, making it practical for immediate application in real-world vehicle systems. Experiments have proven our framework to be a practical solution for achieving robust, energy-efficient control over a variety of driving conditions.</p>
<h3>On-Chip Binary Code Compression and Runtime Uncompressed </h3>
<p><img src=member/hjlee_topic5.jpg align=right width=300> Modern embedded systems, particularly automotive MCUs, face significant memory limitations as software functionality becomes increasingly sophisticated. This research proposes a novel code compression technique that directly manipulates the final compiled output?the Intel HEX format?to overcome these physical hardware constraints. We are developing a custom compression algorithm optimized for the HEX format's structure and implementing an architecture where a bootloader, equipped with decompression logic, uncompresses and executes the application code from Flash memory in real-time at runtime.</p>
<p>Through this approach, we aim to enable much larger software applications to run on existing hardware. A key validation task of this research is to analyze the trade-off between the benefits of memory savings and the performance overhead incurred by real-time decompression. To this end, we plan to use precision analysis equipment like TRACE32 to accurately measure changes in execution time, thereby proving the practicality and efficiency of our proposed technology.</p>
<h2>Publications</h2>
<h3>Journal Publication (<font color=red>SCI</font> 1, <font color=blue>KCI</font> 2)</h3>
<ul>
<li><p>Hyunjung Lee and Daejin Park. <b>Auto Parking Assistant Control using Human-Activity Feedback-based Embedded Software Emulation (<font color=blue>KCI</font>)</b> Journal of the Korea Institute of Information and Communication Engineering, 2024.</p>
</li>
<li><p>Hyunjung Lee and Daejin Park. <b>Real-Time Lightweight Depth Map Estimation Using Stereo Vision and Convolutional Filtering (<font color=blue>KCI</font>)</b> Journal of the Korea Institute of Information and Communication Engineering, 2025.</p>
</li>
<li><p>Hyunjung Lee and Daejin Park. <b>On Preparation (<font color=red>SCI</font>)</b> IEEE Access, 2025.</p>
</li>
</ul>
<h3>Conference Publications (Intl. 5)</h3>
<ul>
<li><p>Hyunjung Lee and Daejin Park. <b>Multi-Camera Interoperable Emulation Framework using Embedded Edge-Cloud AI Computing for Autonomous Vehicle Driving</b> In IEEE Vehicular Networking Conference (VNC), 2024.</p>
</li>
<li><p>Hyunjung Lee and Daejin Park. <b>Convolution-Based Depth Map With Shadow Removal Using Cameras for 3D Mapping in Autonomous Vehicle Driving</b> In IEEE International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS 2024), 2024.</p>
</li>
<li><p>Hyunjung Lee and Daejin Park. <b>Advanced Real-Time Performance QEMU Emulated Automotive Control System with a Multithreaded PID Controller</b> In 2025 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), 2025.</p>
</li>
<li><p>Hyunjung Lee and Daejin Park. <b>Lightweight Empirical Reinforcement Learning Driven Adaptive Super-Twisting Control with Fused Linear-Nonlinear Sliding Surfaces for Embedded Vehicle Control</b> In IEEE 51th Annual Conference of the IEEE Industrial Electronics Society (Flagship Conf. IECON 2025), 2025.</p>
</li>
<li><p>Hyunjung Lee and Daejin Park. <b>Architecture-Aware Neural Compression for TriCore Firmware using Knowledge Distillation (Under Review)</b> In IEEE International Conference on Artificial Intelligence in Information and Communication (ICAIIC 2026), 2026.</p>
</li>
</ul>
<h3>Participation in International Conference</h3>
<ul>
<li><p>IEEE VNC 2024, Kobe, Japan</p>
</li>
<li><p>IEEE ISPACS 2024, Taipei, Taiwan</p>
</li>
<li><p>Automotive World 2025, Tokyo, Japan</p>
</li>
<li><p>IEEE ICCE-TW 2025, Kaosiung, Taiwan </p>
</li>
<li><p>IEEE IECON 2025, Madrid, Spain</p>
</li>
<li><p>IEEE ICAIIC 2025, Tokyo, Japan</p>
</li>
</ul>
<p>Last Updated, 2025.12.05</p>
<div id="footer">
<div id="footer-text">This page was generated by our compiler @ copyright reserved (AI-S<sup><font size=1>2</font></sup>oC Lab<img src=images/logo.jpg width=20 >)
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
